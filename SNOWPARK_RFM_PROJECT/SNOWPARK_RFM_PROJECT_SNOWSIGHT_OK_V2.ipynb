{
 "metadata": {
  "lastEditStatus": {
   "notebookId": "b46brlz6bqgemdp6w6hm",
   "authorId": "9038716052201",
   "authorName": "LEARNINGJOURNEY",
   "authorEmail": "ankit.dataanalyst.14@gmail.com",
   "sessionId": "1300d8d0-1148-4bcf-b85c-bf0a30325f1e",
   "lastEditTime": 1763531011088
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d38537-a602-47f2-bc58-1aaadb2f047d",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "# Snowpark RFM Project — Snowsight (Ready-to-run)\n",
    "\n",
    "This notebook is prepared to run **inside Snowflake Worksheets (Python / Anaconda environment)**. It is self-contained and includes steps to create stages/file formats, load NDJSON/JSON files, run Snowpark DataFrame transformations, compute Top-10 products for October 2025, create RFM features, and persist results to Snowflake tables.\n",
    "\n",
    "**IMPORTANT:** Upload your data files (`FCT_SALES_10000.ndjson` and `DIM_PRODUCT.json`) to the internal stage `@RAW.JSON_STAGE` using the Snowsight stage upload UI before running the **COPY INTO** cell.\n",
    "\n",
    "Generated: November 2025\n",
    "Author: DAGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94557e89-cd6c-4cf9-8719-806f0ebd9403",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "## 1) Prerequisites (Snowflake Worksheets - Python)\n\n- Run this notebook in a **Python worksheet** within Snowsight (Snowflake UI) which has Anaconda integration.\n- No local `pip install` or credentials needed — Snowflake manages the environment and credentials for you.\n- Before running the ingestion cell, upload the files to the stage via the **Data -> Stages -> RAW.JSON_STAGE -> Upload** UI, or use SnowSQL to `PUT` the files to the stage from your local machine.\n\nFiles to upload:\n- `FCT_SALES_10000.ndjson`\n- `DIM_PRODUCT.json`\n"
  },
  {
   "cell_type": "markdown",
   "id": "1b9a5d88-867b-40ca-a596-551b13f47f30",
   "metadata": {
    "name": "cell25"
   },
   "source": [
    "## 2.1) Snowpark Architecture — Client vs Server\n",
    "\n",
    "**Client (Notebook / Snowpark API):**\n",
    "- The client (your Snowsight Python worksheet) builds a logical plan using Snowpark DataFrame operations.\n",
    "- It **does not** execute heavy computations locally; instead it creates a plan to send to Snowflake.\n",
    "\n",
    "**Server (Snowflake Compute Engine):**\n",
    "- Snowflake receives the logical plan and executes it inside its compute layer, pushing down SQL for efficient server-side processing.\n",
    "- Advantages: reduced data transfer, secure execution, and scalable compute.\n",
    "\n",
    "**Demo tips in this notebook:**\n",
    "- Use `.explain()` on a DataFrame to view the SQL plan and confirm server-side pushdown.\n",
    "- Use `.show()` to execute and preview results; avoid `.collect()` on large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f5bbd-7dcc-4c8c-acde-0b6319de60d7",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "# 1) Get Snowpark session inside Snowsight Notebook\n# -------------------------------------------------\n# New Snowflake Notebook runtimes do NOT auto-create a `session` variable.\n# Instead, they provide a function get_active_session() to retrieve the live session.\n# This block works in ALL Snowsight Notebook runtimes.\n\ntry:\n    from snowflake.snowpark.context import get_active_session\n    \n    # Fetch the active Snowflake-managed session\n    session = get_active_session()\n    \n    print(\"Snowpark session acquired via get_active_session().\")\n    print(\"Connected to account:\", session.get_current_account())\n\nexcept Exception as e:\n    print(\"ERROR: Could not obtain the Snowpark session using get_active_session().\")\n    print(\"Details:\", e)\n    raise Exception(\n        \"Your notebook is not running under the Snowflake Python runtime.\\n\"\n        \"Check: Notebook Settings → Runtime → Snowflake Python Runtime\"\n    )\n\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "c0a0f272-4df5-448a-9881-3aaa50ee324d",
   "metadata": {
    "name": "cell4"
   },
   "source": [
    "## 2.2) Create database, schemas, and stage\n",
    "\n",
    "This cell creates `POS_DEMO` database, the `RAW`/`PROD` schemas, and the internal stage `@RAW.JSON_STAGE`. You only need to run it once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a6e2b-794d-4a67-a58b-53f1fe7f6b1e",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "# Create database and schemas\n",
    "session.sql(\"CREATE DATABASE IF NOT EXISTS POS_DEMO\").collect()\n",
    "session.sql(\"CREATE SCHEMA IF NOT EXISTS POS_DEMO.RAW\").collect()\n",
    "session.sql(\"CREATE SCHEMA IF NOT EXISTS POS_DEMO.PROD\").collect()\n",
    "\n",
    "# Create internal stage under RAW schema\n",
    "session.sql(\"CREATE OR REPLACE STAGE POS_DEMO.RAW.JSON_STAGE\").collect()\n",
    "\n",
    "print(\"✅ Database, schemas, and stage ensured: POS_DEMO.RAW.JSON_STAGE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c521d-e08b-4af4-b6a5-850f1889b023",
   "metadata": {
    "name": "cell6"
   },
   "source": [
    "## 3) Create file format and raw table\n",
    "\n",
    "We create a JSON file format and a raw table to load Variant JSON rows. The NDJSON file should be uploaded to `@POS_DEMO.RAW.JSON_STAGE` via Snowsight UI before running the COPY command below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f3f0a-f432-454f-bb0b-2b496e727b67",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "# Create JSON file format\n",
    "session.sql(\"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT POS_DEMO.RAW.FF_JSON_NDJSON\n",
    "  TYPE = 'JSON'\n",
    "  STRIP_OUTER_ARRAY = FALSE\n",
    "\"\"\").collect()\n",
    "\n",
    "# Create raw JSON table\n",
    "session.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE POS_DEMO.RAW.RAW_JSON (raw VARIANT)\n",
    "\"\"\").collect()\n",
    "\n",
    "print(\"✅ File format 'POS_DEMO.RAW.FF_JSON_NDJSON' and table 'POS_DEMO.RAW.RAW_JSON' created successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d832eff-e2c8-4369-8e21-ee972a2b9755",
   "metadata": {
    "name": "cell8"
   },
   "source": [
    "### Upload your files to the stage\n",
    "\n",
    "Use the Snowsight UI: Data → Databases → POS_DEMO → Stages → RAW.JSON_STAGE → **Upload**. Upload both files: `FCT_SALES_10000.ndjson` and `DIM_PRODUCT.json`.\n",
    "\n",
    "After uploading, run the next cell to copy data into the raw table and normalized tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660b367-a62a-4293-84f2-b714297da12b",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": [
    "# Copy FCT_SALES NDJSON lines into RAW_JSON\n",
    "copy_sales = session.sql(\"\"\"\n",
    "COPY INTO POS_DEMO.RAW.RAW_JSON\n",
    "FROM @POS_DEMO.RAW.JSON_STAGE\n",
    "PATTERN = '.*FCT_SALES_10000.ndjson'\n",
    "FILE_FORMAT = (FORMAT_NAME = POS_DEMO.RAW.FF_JSON_NDJSON)\n",
    "ON_ERROR = CONTINUE\n",
    "\"\"\")\n",
    "print(\"COPY INTO raw_json for sales started...\")\n",
    "print(copy_sales.collect()[:3])\n",
    "\n",
    "# Create file format for JSON arrays (if DIM_PRODUCT.json is an array)\n",
    "session.sql(\"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT POS_DEMO.RAW.FF_JSON_ARRAY\n",
    "  TYPE = 'JSON'\n",
    "  STRIP_OUTER_ARRAY = TRUE\n",
    "\"\"\").collect()\n",
    "\n",
    "# Copy DIM_PRODUCT JSON array\n",
    "copy_prod = session.sql(\"\"\"\n",
    "COPY INTO POS_DEMO.RAW.RAW_JSON\n",
    "FROM @POS_DEMO.RAW.JSON_STAGE\n",
    "PATTERN = '.*DIM_PRODUCT.json'\n",
    "FILE_FORMAT = (FORMAT_NAME = POS_DEMO.RAW.FF_JSON_ARRAY)\n",
    "ON_ERROR = CONTINUE\n",
    "\"\"\")\n",
    "print(\"COPY INTO raw_json for products started...\")\n",
    "print(copy_prod.collect()[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7588e81-9f72-44e0-9314-e582998bd926",
   "metadata": {
    "name": "cell10"
   },
   "source": [
    "## 5) Normalize RAW JSON into structured tables\n",
    "\n",
    "We will extract fields from the Variant `raw` column and insert into `FCT_SALES` and `DIM_PRODUCT` structured tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f35eaad-0f0a-441e-b9b2-50000f56adea",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "# 5a) Create structured FCT_SALES and DIM_PRODUCT tables separately\nsession.sql(\"\"\"\nCREATE OR REPLACE TABLE POS_DEMO.RAW.FCT_SALES (\n  SALE_ID STRING,\n  CUSTOMER_ID STRING,\n  PRODUCT_ID STRING,\n  SALE_DATE DATE,\n  QUANTITY NUMBER,\n  UNIT_PRICE FLOAT,\n  TOTAL_AMOUNT FLOAT,\n  REGION STRING\n)\n\"\"\").collect()\n\nsession.sql(\"\"\"\nCREATE OR REPLACE TABLE POS_DEMO.RAW.DIM_PRODUCT (\n  PRODUCT_ID STRING,\n  PRODUCT_NAME STRING,\n  CATEGORY STRING,\n  BRAND STRING,\n  PRICE FLOAT\n)\n\"\"\").collect()\n\nprint('✅ Structured tables POS_DEMO.RAW.FCT_SALES and POS_DEMO.RAW.DIM_PRODUCT created successfully.')\n\n\n# 5b) Insert sales rows\ninsert_sales = session.sql(\"\"\"\nINSERT INTO POS_DEMO.RAW.FCT_SALES (SALE_ID, CUSTOMER_ID, PRODUCT_ID, SALE_DATE, QUANTITY, UNIT_PRICE, TOTAL_AMOUNT, REGION)\nSELECT\n  raw:\"SALE_ID\"::STRING,\n  raw:\"CUSTOMER_ID\"::STRING,\n  raw:\"PRODUCT_ID\"::STRING,\n  TO_DATE(raw:\"SALE_DATE\"::STRING,'YYYY-MM-DD'),\n  raw:\"QUANTITY\"::NUMBER,\n  raw:\"UNIT_PRICE\"::FLOAT,\n  raw:\"TOTAL_AMOUNT\"::FLOAT,\n  raw:\"REGION\"::STRING\nFROM POS_DEMO.RAW.RAW_JSON\nWHERE raw:\"SALE_ID\" IS NOT NULL;\n\"\"\")\n\nprint('✅ Inserted sales rows into FCT_SALES.')\nprint(insert_sales.collect()[:3])\n\n\n# 5c) Insert ONLY product rows (FIXED)\ninsert_prod = session.sql(\"\"\"\nINSERT INTO POS_DEMO.RAW.DIM_PRODUCT (PRODUCT_ID, PRODUCT_NAME, CATEGORY, BRAND, PRICE)\nSELECT\n  raw:\"PRODUCT_ID\"::STRING,\n  raw:\"PRODUCT_NAME\"::STRING,\n  raw:\"CATEGORY\"::STRING,\n  raw:\"BRAND\"::STRING,\n  raw:\"PRICE\"::FLOAT\nFROM POS_DEMO.RAW.RAW_JSON\nWHERE raw:\"PRODUCT_NAME\" IS NOT NULL;   -- FIXED HERE\n\"\"\")\n\nprint('✅ Inserted product rows into DIM_PRODUCT.')\nprint(insert_prod.collect()[:3])\n\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "faa4a469-3117-4cfc-9184-9e844c38c564",
   "metadata": {
    "name": "cell12"
   },
   "source": [
    "## 6) Quick Validation\n",
    "\n",
    "Check counts and a few sample rows to ensure data loaded correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abae45-6dd8-4aaa-9863-99795a9063f1",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "# Quick checks\n",
    "print('Total sales rows:', session.sql('SELECT COUNT(*) FROM POS_DEMO.RAW.FCT_SALES').collect())\n",
    "print('Distinct products:', session.sql('SELECT COUNT(DISTINCT PRODUCT_ID) FROM POS_DEMO.RAW.FCT_SALES').collect())\n",
    "print('Sample sales rows:')\n",
    "print(session.sql('SELECT * FROM POS_DEMO.RAW.FCT_SALES LIMIT 5').collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ad55c-edab-49fb-a94d-178c4236dfc5",
   "metadata": {
    "name": "cell14"
   },
   "source": [
    "## 7) Snowpark DataFrame Examples — select, filter, join (Lazy vs Eager)\n\nThis section demonstrates building a lazy expression (no execution) and triggering execution with `.show()` and `.count()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c9494-6e17-473d-9b3f-fbbc9a2f4d42",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "# Load tables as DataFrames\n",
    "sales_df = session.table('POS_DEMO.RAW.FCT_SALES')\n",
    "prod_df = session.table('POS_DEMO.RAW.DIM_PRODUCT')\n",
    "\n",
    "# SALE_DATE is already DATE type — no need to re-convert\n",
    "# sales_df = sales_df.with_column('SALE_DATE', to_date(col('SALE_DATE'), 'YYYY-MM-DD'))  ❌ REMOVE THIS\n",
    "\n",
    "# Build lazy expression\n",
    "expr = sales_df.select('SALE_ID','CUSTOMER_ID','PRODUCT_ID','SALE_DATE','QUANTITY','TOTAL_AMOUNT') \\\n",
    "               .filter(col('TOTAL_AMOUNT') > 0)\n",
    "\n",
    "print('Built expression (lazy). Now trigger a small action:')\n",
    "expr.show(5)\n",
    "print('Count of expression (executes on server):', expr.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a081af3-e50f-46ea-b0af-216654fb23e4",
   "metadata": {
    "name": "cell16"
   },
   "source": [
    "## 8) Aggregation — Top 10 Selling Products for October 2025\n",
    "\n",
    "Compute total quantity and sales for each product during Oct 1–31, 2025 and join with DIM_PRODUCT to show names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab9538-8cee-473c-981a-56c18cf3b5ba",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "\n",
    "from snowflake.snowpark.functions import sum as ssum, lit, col\n",
    "\n",
    "last_month_start = '2025-10-01'\n",
    "last_month_end = '2025-10-31'\n",
    "\n",
    "top10_oct = (\n",
    "    sales_df\n",
    "    .filter((col('SALE_DATE') >= lit(last_month_start)) & (col('SALE_DATE') <= lit(last_month_end)))\n",
    "    .group_by('PRODUCT_ID')\n",
    "    .agg(\n",
    "        ssum(col('QUANTITY')).alias('TOTAL_QTY'),\n",
    "        ssum(col('TOTAL_AMOUNT')).alias('TOTAL_SALES')\n",
    "    )\n",
    "    .order_by(col('TOTAL_SALES').desc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "# Join with product names\n",
    "top10_with_name = (\n",
    "    top10_oct\n",
    "    .join(prod_df, top10_oct['PRODUCT_ID'] == prod_df['PRODUCT_ID'], how='left')\n",
    "    .select(top10_oct['PRODUCT_ID'], prod_df['PRODUCT_NAME'], col('TOTAL_QTY'), col('TOTAL_SALES'))\n",
    "    .order_by(col('TOTAL_SALES').desc())\n",
    ")\n",
    "\n",
    "print('Top 10 selling products in Oct 2025:')\n",
    "top10_with_name.show(10)   # ✅ No truncate arg\n",
    "\n",
    "# Optional: pretty full output\n",
    "# print(top10_with_name.to_pandas())\n",
    "\n",
    "# Persist top10\n",
    "session.sql('CREATE SCHEMA IF NOT EXISTS POS_DEMO.PROD').collect()\n",
    "top10_with_name.write.mode('overwrite').save_as_table('POS_DEMO.PROD.TOP10_PRODUCTS_OCT2025')\n",
    "print('✅ Saved POS_DEMO.PROD.TOP10_PRODUCTS_OCT2025')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1689e77d-f394-414e-ad94-e1915699294a",
   "metadata": {
    "name": "cell18"
   },
   "source": [
    "## 9) RFM Feature Engineering\n",
    "\n",
    "Compute LAST_PURCHASE_DATE, RECENCY_DAYS (relative to analysis date), FREQUENCY, and MONETARY for each customer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f470c3d-bfc9-46ac-83d1-83b8a76ed162",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import col, max as smax, count as scount, sum as ssum, datediff, lit\n",
    "\n",
    "analysis_date = '2025-11-04'\n",
    "\n",
    "rfm_df = (\n",
    "    sales_df\n",
    "    .group_by('CUSTOMER_ID')\n",
    "    .agg(\n",
    "        smax(col('SALE_DATE')).alias('LAST_PURCHASE_DATE'),\n",
    "        scount(col('SALE_ID')).alias('FREQUENCY'),\n",
    "        ssum(col('TOTAL_AMOUNT')).alias('MONETARY')\n",
    "    )\n",
    "    .with_column('RECENCY_DAYS', datediff('day', col('LAST_PURCHASE_DATE'), lit(analysis_date)))\n",
    "    .select('CUSTOMER_ID', 'LAST_PURCHASE_DATE', 'RECENCY_DAYS', 'FREQUENCY', 'MONETARY')\n",
    ")\n",
    "\n",
    "print('Preview RFM (top by monetary):')\n",
    "rfm_df.order_by(col('MONETARY').desc()).show(10)\n",
    "\n",
    "# Persist RFM results\n",
    "rfm_df.write.mode('overwrite').save_as_table('POS_DEMO.PROD.RFM_CUSTOMER_FEATURES')\n",
    "print('✅ Saved POS_DEMO.PROD.RFM_CUSTOMER_FEATURES')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d266e-1ce8-4c8e-9e6f-065d0f98d3ef",
   "metadata": {
    "name": "cell20"
   },
   "source": [
    "## 10) Churn Label & Export for Modeling\n",
    "\n",
    "We define a simple churn label: `CHURN_LABEL = 1 if RECENCY_DAYS > 30 else 0`.\n",
    "\n",
    "**Note:** If you want to export to CSV for model training locally, you can `to_pandas()` a small dataset. Avoid pulling large tables to client in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61caae-5c33-462b-8760-6c96b10a11f7",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "# Add CHURN_LABEL server-side and show distribution\n",
    "from snowflake.snowpark.functions import when\n",
    "\n",
    "rfm_labeled = rfm_df.with_column('CHURN_LABEL', when(col('RECENCY_DAYS') > 30, 1).otherwise(0))\n",
    "print('Churn label distribution:')\n",
    "print(rfm_labeled.group_by('CHURN_LABEL').count().order_by('CHURN_LABEL').collect())\n",
    "\n",
    "# Example: write labeled data to PROD for downstream ML\n",
    "rfm_labeled.write.mode('overwrite').save_as_table('POS_DEMO.PROD.RFM_CUSTOMER_FEATURES_LABELED')\n",
    "print('Saved POS_DEMO.PROD.RFM_CUSTOMER_FEATURES_LABELED')\n",
    "\n",
    "# If you need CSV, export using a stage (example writes to table, then user can unload to stage with COPY INTO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae622c8a-0600-4d76-9760-e6e151680a82",
   "metadata": {
    "name": "cell22"
   },
   "source": [
    "## 11) Validation & Explain Plans\n",
    "\n",
    "Run these quick checks and view the execution plan to confirm server-side pushdown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb40b0-439a-4bac-a662-283b6ee12e4b",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "# Validation checks\n",
    "print('FCT_SALES count:', session.table('POS_DEMO.RAW.FCT_SALES').count())\n",
    "print('Distinct products:', session.table('POS_DEMO.RAW.FCT_SALES').select('PRODUCT_ID').distinct().count())\n",
    "print('RFM rows:', session.table('POS_DEMO.PROD.RFM_CUSTOMER_FEATURES').count())\n",
    "\n",
    "# Show explain for top10 query\n",
    "print('\\nTop10 explain plan:')\n",
    "print(top10_with_name.explain())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96571db6-e90f-47f5-8589-61ad18dd697c",
   "metadata": {
    "name": "cell24"
   },
   "source": [
    "## 12) Next Steps & Cleanup\n",
    "\n",
    "- Extend features: average order value (`MONETARY/FREQUENCY`), tenure, recency buckets, rolling features.\n",
    "- For production, consider clustering on `CUSTOMER_ID` or `SALE_DATE` for performance.\n",
    "- To clean up created objects (optional), run DROP statements for the tables/stage.\n"
   ]
  }
 ]
}
